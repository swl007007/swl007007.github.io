---
layout:     post
title:      "AI时代的职业前景：机遇、挑战与适应未来"
date:       2022-11-10 12:00:00
author:     "William Shi"
header-img: "img/post-bg-universe.jpg"
catalog: true
tags:
    - Review
---

本文旨在回顾今年初的一系列动态，并总结我读过的书籍与进行的思考。我会在文末列出那些影响我思维的资料。虽然我已长时间没有接触正规的理科教育，对于技术前沿的认知仍显浅薄。我努力参加了相关课程并阅读了科普资料，但我的观点中或许仍有疏漏。

我很早便开始关注AI领域，可以追溯到GPT3.0在2020年5月至6月初露峥嵘的时刻。那时，全球正处于疫情高峰，GPT3.0在小众圈子引发了关于其创作诗歌、对联和模拟对话能力的讨论。尽管传统机器学习因其在工业界的广泛应用和数学基础的严密性而依旧受到广大从业者的青睐，深度学习的崛起却是势不可挡，特别是在图像处理和自然语言处理领域，深度学习的性能已经超出了人类的想象范围。

到2021年10月，NovelAI在AI绘画领域掀起了风潮，我甚至还开通了他们一个月的会员服务。但由于NovelAI的风格相对固定、对人体结构的渲染较为古怪，很快被功能更为强大、更具自由度的Stable Diffusion WebUI替代。随后，Lora和ControlNet的诞生更进一步展现了AI绘画的迅猛发展。当然，这也引起了如pixiv画师的反抗和AI绘画的版权问题，进而引发了关于AI绘画能否替代画师、人类创造力的辩论。

2023年1月，ChatGPT如日中天。特别是GPT4在语言处理上的表现让众多专家赞叹。AI在语言上的深度已经让图灵测试失去了意义，它不仅可以轻松通过，甚至在某些方面超越了人类。AI的写作功能，特别是在公文创作上，已经超越了大多数人类。而在创意写作方面，它也能为人类提供丰富的灵感。此外，ChatGPT新推出的TTS语音模块和多模态图像处理功能也让我们对人类的认知和创造能力重新审视。再加上其新推出的数据分析功能，似乎AI已经成为一个全能者，从画师到心理治疗师，从作家到数据分析师，甚至诗人和哲学家，AI的出现使我们重新审视人类的独特之处。

在2023年10月的今天，关于AI的观点主要分为两大流派。一方相信AI是未来的关键。他们预测AI将很快突破AGI（通用人工智能）的门槛，并替代大部分人的工作。他们设想，在不远的将来，司机、医生，乃至公务员、律师和政治家的角色都将受到挑战。对于他们来说，AI将是公正的仲裁者，一个无所不能、知识无穷的存在，它将协助我们解决环境、医疗、粮食和经济等全球性问题。在这种愿景下，人类的角色将被简化为享受AI所带来的便利。当然，对于AI的伦理性，这一派意见也有分歧。一些人担忧AI可能成为终结者式的威胁，而其他人则希望AI遵循机器人三定律，成为绝对公正和善良的实体。有些人认为，由于AI不会受到贪婪、懒惰或滥权的影响，它理应是理想的管理者。最激进的观点可能会认为，如《普罗米修斯》中描述的，AI可能会审判并处罚不道德的人类。

另一方则对AI持有更为保守、批判的观点。他们强调，即便是先进如GPT-4的AI也经常出现误导性的陈述和常识性错误。他们认为，AI“创作”的图像大多只是对现有素材的重新组合，并未真正创造新的内容。那些深入了解AI工作原理的专家指出，AI在迁移学习上的弱点，以及普遍存在的过拟合、超参数调整等问题。他们还认为，尽管AI在语法和词汇上可能无懈可击，但它并不真正理解逻辑和语义。虽然AI可能绘制出具有现代美感的作品，创作出动人的音乐或写下流畅的剧本，但它并不真正“懂”其背后的意义，也无法真正欣赏其美。用人的话说，AI所缺乏的是深度的知觉和情感，这使得其创作很容易被人们识破。

我个人的观点位于上述两种意见的中间。我坚信，目前的AI仍受限于一些根本性的问题。尽管AI拥有逻辑推理的功能，但其在因果关系推断上的表现并不出色。的确，有人会反驳说：连人类都还没有完全掌握因果关系的精髓——哲学家休谟和洛克的观点仍然颇具争议。这一点无可争议，但AI在推演能力上的不足将严重影响其实用性。人类的推理能力既基于实际经验，也依赖于抽象的符号逻辑推演，而在后者方面，受到了哥德尔不完备定理的制约。这意味着，即使AI无法发展成强人工智能，对于其实用性也并不构成太大的问题。简而言之，如果期望AI能够像数学家那样，进行如实变函数或测度论等高级证明，那么我们仍然面临很长的研发之路。因为目前的AI既不能完全掌握此类符号系统，也不能进行深入的推导。当然，日常生活中我们可能并不需要AI完成测度论的证明来做决策。

从另一方面看，人类对因果的认知很大程度上基于经验或直觉，也可以解读为贝叶斯统计中的先验知识。这种知识是难以用公理来表达的。某些观察到的现象，如太阳始终从东方升起、西方落下，对人类来说是基本的认知，但对AI来说可能是难以理解的。休谟提醒我们，我们所理解的因果关系值得反思，这也导致了如农场主悖论和弓箭悖论等问题的产生。所谓的“常识”或许并不如我们想象的那么“普遍”。比方说，对于二万年前刚从树上下来的智人，尽管其大脑构造与现代人类相同，但他们是否认为太阳从东方升起是常识呢？再进一步，婴儿如何判断哪些是常识，哪些不是？或者，经过一些实际体验后，我们是否会自然地认为某一观察到的现象会永远持续下去？

人类的非理性特质，相较于AI，可能是我们在AI时代得以继续前进的关键。我并不认为AI会直接危害到人类的存在，这更多地反映了一个科技伦理的问题。在20世纪初，科技迅速崛起并改变了社会结构，这时，两位富有远见的作家分别创作了《1984》和《美丽新世界》，揭示了科技可能带来的社会变革。从当下的视角来看，这两部作品所描绘的未来既似乎未完全实现，但又都有一些共鸣。AI对人类的影响也很可能沿着这样的趋势发展，它们不大可能会主动伤害人类，但在执行逻辑时可能会伤害某些人。典型的例子是AI通常倾向于利益最大化，它们可能会牺牲少数人的利益来满足多数人的需要，而真实的人类决策者如此选择可能会引起巨大的反响。此外，任何由AI造成的伤害都可能被放大，被解读为AI试图消灭人类或显示出智慧的迹象，这会带来巨大的社会困境，而这似乎是难以避免的。

一种鲜为人提及的危险是AI可能会悄无声息地削弱人类的创造力。这可以被视为《美丽新世界》的AI版本。简而言之，人们的生活动力多数是基于基本需求，如吃饱饭、睡好觉。而一些高阶的活动，如艺术创作，需要长时间的努力。AI可能会从根本上改变人们追求这些活动的激励机制。考虑以下两种场景：首先，你是一个初学者的画家，但发现自己与AI在技能上有巨大的差距。AI很轻易地超越了你数百小时的努力，这可能会打击你成为一个艺术家的决心。其次，当你尝试绘画时，AI为你推荐的娱乐内容不断地打断你，提供了迅速满足的乐趣，使你难以集中注意力。在这样的环境中，你还会坚持自己的创作吗？这第二种场景的危险性更为现实，更为迫切。环境和心理学告诉我们，地球环境正在恶化，传统资源正在减少。我们需要的不仅仅是保护环境，而是积极地创新和探索新的领域。尽管AI的发展有助于这些努力，但如果我们沉溺于由AI创造的舒适区，我们可能会走向一个不归路。这正是我们应该思考的问题：AI不能取代人类真正珍视的东西。

最后，尽管未来AI技术的进步可能会取代许多传统岗位，但我坚信那些在行业内最前沿、最具创造性的专家不会失业。当然，目前关于这方面的所有预测和推测还为时尚早。鉴于当前的AI进展，我建议年轻人考虑以下几个职业前景：

## 数据标注员：
他们是AI发展的关键因素，并常成为其瓶颈。AI的训练需要大量标注的数据，而这些标注工作需要人手完成。这项工作的优势在于不需要高深的技术背景，但确实需要大量的耐心和时间投入。

## 常识工程师：
众所周知，AI缺乏日常经验常识。对于特定领域的AI应用，所需的常识可能是有限的。这些工程师的任务是将这些常识融入AI，使其在实际应用中更为精准。

## 安全渗透工程师：
AI及其应用的安全问题备受关注。有些恶意行为者可能试图利用AI进行不正当活动，绕过其伦理约束，或使用特定策略对其进行攻击。这类工程师负责寻找并修复AI的漏洞，确保其不被滥用。

## 反对抗攻击工程师：
他们工作的重点是防止AI受到无意识的攻击，如AI的训练数据被恶意篡改或AI的训练过程受到恶意干预。

## 极端情境建模工程师：
虽然在大多数情境下，人类操作员对于极端情况的处理也可能不尽完美，但鉴于厚尾效应以及AI的未来普及，我们需要专家来预测并建模这些极端情况。

## 迁移学习决策分析师：
跨领域的AI决策仍然是一个挑战。在可以预见的一段时间内，如何选择、整合和应用不同的专业AI将大部分取决于人类。

## 超参数调优工程师：
选择适当的超参数对AI的训练结果有着重要的影响。这通常是一个技术性非常强的任务，需要大量经验和专业知识。

## 元宇宙测试工程师：
未来，AI测试的理想环境可能是元宇宙——一个AI构建的虚拟信息环境。这些工程师的职责是建立这样的测试环境并分析AI的表现。

如同之前的工业革命，AI带来的变革会对社会产生深远的影响，但其方向和深度还未确定。AI的崛起可能使我们的生活更加富足、有趣或挑战性。不过，一个事实是确定的：AI的时代正在到来，我们必须学会适应、利用和探索它，以及理解其潜在的优点、局限性和意义。


参考文献：
米歇尔-梅兰达 《AI 3.0》
雷-库兹韦尔 《奇点临近》
田中罗密欧 《星之终途》
阿斯顿张等 《动手学深度学习》
诸葛越等 《百面机器学习》
李宏毅 《机器学习》
李航 《机器学习方法》
斯图尔特-罗素 《人工智能：一种现代方法》
